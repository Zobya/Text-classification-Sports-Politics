{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c82178f",
   "metadata": {},
   "source": [
    "## Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbdb5245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category filename                              title  \\\n",
      "0  business  001.txt  Ad sales boost Time Warner profit   \n",
      "1  business  002.txt   Dollar gains on Greenspan speech   \n",
      "2  business  003.txt  Yukos unit buyer faces loan claim   \n",
      "3  business  004.txt  High fuel prices hit BA's profits   \n",
      "4  business  005.txt  Pernod takeover talk lifts Domecq   \n",
      "\n",
      "                                             content  \n",
      "0   Quarterly profits at US media giant TimeWarne...  \n",
      "1   The dollar has hit its highest level against ...  \n",
      "2   The owners of embattled Russian oil giant Yuk...  \n",
      "3   British Airways has blamed high fuel prices f...  \n",
      "4   Shares in UK drinks and food firm Allied Dome...  \n",
      "Index(['category', 'filename', 'title', 'content'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Inspecting BBC news dataset (downloaded from kaggle)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"bbc-news-data.csv\", sep=\"\\t\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d289c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports articles: 511\n",
      "Politics articles: 417\n"
     ]
    }
   ],
   "source": [
    "# Now filtering categories to extract Sports and Politics news\n",
    "sports_df = df[df[\"category\"] == \"sport\"]\n",
    "politics_df = df[df[\"category\"] == \"politics\"]\n",
    "\n",
    "#Printing number of articles in sports and politics\n",
    "print(\"Sports articles:\", len(sports_df))\n",
    "print(\"Politics articles:\", len(politics_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f7056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files created successfully.\n"
     ]
    }
   ],
   "source": [
    "sports_texts = sports_df[\"content\"].tolist()\n",
    "politics_texts = politics_df[\"content\"].tolist()\n",
    "\n",
    "with open(\"data/sports.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for article in sports_texts:\n",
    "        f.write(article.replace(\"\\n\", \" \") + \"\\n\")\n",
    "\n",
    "with open(\"data/politics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for article in politics_texts:\n",
    "        f.write(article.replace(\"\\n\", \" \") + \"\\n\")\n",
    "\n",
    "print(\"Files created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe1a4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 928\n",
      "Sports lines: 511\n",
      "Politics lines: 417\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "\n",
    "sports_file = \"data/sports.txt\"\n",
    "politics_file = \"data/politics.txt\"\n",
    "\n",
    "document_lines = []\n",
    "labels = []\n",
    "\n",
    "# Label convention:\n",
    "# 1 = Sports\n",
    "# 0 = Politics\n",
    "\n",
    "# Reading sports documents\n",
    "with open(sports_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            document_lines.append(line)\n",
    "            labels.append(1)\n",
    "\n",
    "# Reading politics documents\n",
    "with open(politics_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            document_lines.append(line)\n",
    "            labels.append(0)\n",
    "\n",
    "print(\"Total lines:\", len(document_lines))\n",
    "print(\"Sports lines:\", labels.count(1))\n",
    "print(\"Politics lines:\", labels.count(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd79bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset contains 511 sports articles and 417 politics articles, resulting in a mildly imbalanced distribution (~55% sports, ~45% politics). Stratified train-test splitting was used to preserve class proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d130ed",
   "metadata": {},
   "source": [
    "## Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea054b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 742\n",
      "Testing samples: 186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    document_lines,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels   # keeps class balance\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", len(X_train))\n",
    "print(\"Testing samples:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeddae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF representation was chosen as it provides better weighting of informative terms compared to raw frequency counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cde61",
   "metadata": {},
   "source": [
    "## Using TF-IDF feature representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "344d30ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature shape: (742, 15219)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF with unigrams only\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1))  # unigrams only\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF feature shape:\", X_train_tfidf.shape) #prints training samples and vocabulary size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060ee49",
   "metadata": {},
   "source": [
    "## Model 1: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "421f3ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9946236559139785\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        84\n",
      "           1       0.99      1.00      1.00       102\n",
      "\n",
      "    accuracy                           0.99       186\n",
      "   macro avg       1.00      0.99      0.99       186\n",
      "weighted avg       0.99      0.99      0.99       186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8185cd",
   "metadata": {},
   "source": [
    "## Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bb081d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9946236559139785\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        84\n",
      "           1       0.99      1.00      1.00       102\n",
      "\n",
      "    accuracy                           0.99       186\n",
      "   macro avg       1.00      0.99      0.99       186\n",
      "weighted avg       0.99      0.99      0.99       186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985da152",
   "metadata": {},
   "source": [
    "## Model 3: Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f7bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        84\n",
      "           1       1.00      1.00      1.00       102\n",
      "\n",
      "    accuracy                           1.00       186\n",
      "   macro avg       1.00      1.00      1.00       186\n",
      "weighted avg       1.00      1.00      1.00       186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Linear SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e4b58",
   "metadata": {},
   "source": [
    "## Model 4: Bi-grams + SVM \n",
    "(TF-IDF with unigram + Bigram instead of TF_IDF for feature extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e8ed07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF (1,2) feature shape: (742, 142149)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF with unigrams + bigrams\n",
    "tfidf_bigram = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X_train_bigram = tfidf_bigram.fit_transform(X_train)\n",
    "X_test_bigram = tfidf_bigram.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF (1,2) feature shape:\", X_train_bigram.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e02f2145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary is larger now because it includes phrases now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945420e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM (TF-IDF 1,2) Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        84\n",
      "           1       1.00      1.00      1.00       102\n",
      "\n",
      "    accuracy                           1.00       186\n",
      "   macro avg       1.00      1.00      1.00       186\n",
      "weighted avg       1.00      1.00      1.00       186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "svm_bigram = LinearSVC()\n",
    "svm_bigram.fit(X_train_bigram, y_train)\n",
    "\n",
    "y_pred_bigram = svm_bigram.predict(X_test_bigram)\n",
    "\n",
    "print(\"Linear SVM (TF-IDF 1,2) Accuracy:\", accuracy_score(y_test, y_pred_bigram))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_bigram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb528801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
